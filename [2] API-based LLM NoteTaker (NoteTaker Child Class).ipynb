{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7d4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.1\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ff05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296be97",
   "metadata": {},
   "source": [
    "- Load the `.txt` file that contains your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c57d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/Input/api-key.txt', 'r') as file:\n",
    "    api_key = file.read()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d6030",
   "metadata": {},
   "source": [
    "# Part III: NoteTaker Child Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff87fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OpenAI_Transcriber import *\n",
    "from OpenAI_Summarizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cad3b6",
   "metadata": {},
   "source": [
    "# `OpenAI_NoteTaker`\n",
    "\n",
    "The child class and the namesake of this repository, the `OpenAI_NoteTaker` has the following methods:\n",
    "- `__init__`: Initializes an instance of the OpenAI_NoteTaker class with the specified input directory, transcriber and summarizer models, and pricing information.\n",
    "\n",
    "- `take_notes`: Converts audio files in the specified input directory to text using the OpenAI transcription API and generates a summary of the resulting text using the OpenAI summarization API.\n",
    "\n",
    "- `save_notes`: Saves the transcription and summary texts generated by take_notes() to text files in the specified directories.\n",
    "\n",
    "- `get_total_job_price`: Calculates the total cost of the transcription and summarization services used, and prints a breakdown of the costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54dc4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAI_NoteTaker(OpenAI_Transcriber, OpenAI_Summarizer):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_dir:str, \n",
    "                 transcriber_model:str = \"whisper-1\", \n",
    "                 USD_per_min:float = 0.006, \n",
    "                 summarizer_model:str = \"gpt-3.5-turbo\", \n",
    "                 USD_per_1k:float = 0.002, \n",
    "                 encoding_name:str = \"cl100k_base\"):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the OpenAI_NoteTaker class.\n",
    "\n",
    "        Args:\n",
    "            input_dir (str): The path to the directory containing the audio files to be transcribed and summarized.\n",
    "            transcriber_model (str, optional): The name of the OpenAI transcription model to use. Defaults to \"whisper-1\".\n",
    "            USD_per_min (float, optional): The price per minute charged by the transcription model, in USD. Defaults to 0.006.\n",
    "            summarizer_model (str, optional): The name of the OpenAI summarization model to use. Defaults to \"gpt-3.5-turbo\".\n",
    "            USD_per_1k (float, optional): The price per 1,000 tokens charged by the summarization model, in USD. Defaults to 0.002.\n",
    "            encoding_name (str, optional): The name of the character-level encoding used by the summarization model. Defaults to \"cl100k_base\".\n",
    "        \"\"\"\n",
    "        super().__init__(input_dir=input_dir, \n",
    "                         transcriber_model=transcriber_model, \n",
    "                         USD_per_min=USD_per_min,  \n",
    "                        )\n",
    "        \"\"\"\n",
    "        Initializes an instance of the OpenAI_Transcriber class.\n",
    "\n",
    "        Args:\n",
    "            input_dir (str): The path to the directory containing the audio files to be transcribed.\n",
    "            transcriber_model (str): The name of the OpenAI transcription model to use.\n",
    "            USD_per_min (float): The price per minute charged by the transcription model, in USD.\n",
    "        \"\"\"\n",
    "        self.summarizer_model = summarizer_model\n",
    "        self.USD_per_1k = USD_per_1k\n",
    "        self.encoding_name = encoding_name\n",
    "        \n",
    "    \n",
    "    def take_notes(self, \n",
    "                   system_prompt:str=None, \n",
    "                   n_items:int=None,\n",
    "                   convert2mp3:bool = False,\n",
    "                   export_mp3_dir:str = None, \n",
    "                   show_transcription:bool=False,\n",
    "                   show_notes:bool=False):\n",
    "        \"\"\"\n",
    "        Transcribes an audio file, summarizes the transcript, and displays the summary.\n",
    "\n",
    "        Args:\n",
    "            system_prompt (str, optional): The prompt that is used to generate the summary. Defaults to None.\n",
    "            n_items (int, optional): The number of summary items to display. Defaults to None.\n",
    "            convert2mp3 (bool, optional): If True, the audio file is converted to an MP3 file before transcription. Defaults to False.\n",
    "            export_mp3_dir (str, optional): The directory where the MP3 file is exported, if it is converted. Defaults to None.\n",
    "            show_transcription (bool, optional): If True, the transcription text is printed to the console. Defaults to False.\n",
    "            show_notes (bool, optional): If True, the summary is printed to the console. Defaults to False.\n",
    "\n",
    "        Methods:\n",
    "            - to_mp3(export_dir:str=None): Converts the audio file to an MP3 file and saves it to the specified export directory.\n",
    "            - get_filesize(): Returns the size of the audio file in bytes.\n",
    "            - get_duration(): Returns the duration of the audio file in seconds.\n",
    "            - transcribe_audio(show_output:bool=False): Transcribes the audio file and saves the transcription text to a class attribute.\n",
    "            - summarize_text(system_prompt:str=None, n_items:int=None, show_notes:bool=False): Generates a summary of the transcription text using the OpenAI API and saves the summary to a class attribute.\n",
    "            - save_txt(export_dir:str=None): Saves the transcription or summary text to a .txt file in the specified export directory.\n",
    "\n",
    "        Examples:\n",
    "            # Initialize the OpenAI_NoteTaker class with the input directory and summarizer model\n",
    "            note_taker = OpenAI_NoteTaker(input_dir='path/to/input', summarizer_model='gpt-3')\n",
    "            \n",
    "            # Define role_txt for system_prompt\n",
    "            role_txt = \"'You are a graduating SHS student, excellent at summarizing notes in layman's terms.\"\n",
    "\n",
    "            # Transcribe the audio file, summarize the transcription, and display the summary\n",
    "            note_taker.take_notes(system_prompt=role_txt, n_items=3, show_transcription=True, show_notes=True)\n",
    "\n",
    "        Attributes:\n",
    "            - input_dir (str): The directory where the input audio file is located.\n",
    "            - transcriber_model (str): The name of the OpenAI API model used for transcription.\n",
    "            - USD_per_min (float): The cost in USD per minute of audio transcribed using the OpenAI API.\n",
    "            - summarizer_model (str): The name of the OpenAI API model used for summarization.\n",
    "            - USD_per_1k (float): The cost in USD per 1000 tokens generated by the OpenAI API.\n",
    "            - encoding_name (str): The name of the encoding used by the OpenAI API for summarization.\n",
    "            - Transcriber (OpenAI_Transcriber): An instance of the OpenAI_Transcriber class.\n",
    "            - Transcribed_Audio (str): The text of the audio transcription.\n",
    "            - Summarizer (OpenAI_Summarizer): An instance of the OpenAI_Summarizer class.\n",
    "        \"\"\"\n",
    "        self.Transcriber = OpenAI_Transcriber(input_dir = self.input_dir, \n",
    "                                              transcriber_model = self.transcriber_model, \n",
    "                                              USD_per_min = self.USD_per_min)\n",
    "        if convert2mp3==True:\n",
    "            self.Transcriber.to_mp3(export_dir=export_mp3_dir)\n",
    "        \n",
    "        self.Transcriber.get_filesize()\n",
    "        self.Transcriber.get_duration()\n",
    "        \n",
    "        self.Transcriber.transcribe_audio(show_output=show_transcription)\n",
    "        \n",
    "        self.Transcribed_Audio = self.Transcriber.transcript_text\n",
    "        \n",
    "        self.Summarizer = OpenAI_Summarizer(transcript_text = self.Transcribed_Audio, \n",
    "                                            summarizer_model = self.summarizer_model, \n",
    "                                            USD_per_1k = self.USD_per_1k, \n",
    "                                            encoding_name = self.encoding_name)\n",
    "\n",
    "        self.Summarizer.num_tokens_from_input_string()\n",
    "        print(f\"Input transcription tokens: {self.Summarizer.input_num_tokens}\\n\")\n",
    "        \n",
    "        if show_notes==True:\n",
    "            print(f\"NoteTaker's Summary in {n_items} points: \\n\")\n",
    "            \n",
    "        self.Summarizer.summarize_text(system_prompt = system_prompt, \n",
    "                                       n_items = n_items, \n",
    "                                       show_notes = show_notes)\n",
    "        \n",
    "    def save_notes(self, \n",
    "                   export_transcription_dir:str=None, \n",
    "                   export_summary_dir:str=None):\n",
    "        \"\"\"\n",
    "        Saves the transcribed text and summary to text files at the specified directory.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        export_transcription_dir : str, optional\n",
    "            The directory to export the transcribed text file to.\n",
    "        \n",
    "        export_summary_dir : str, optional\n",
    "            The directory to export the summary text file to.\n",
    "            \n",
    "        Examples:\n",
    "        ---------\n",
    "        # Define role_txt for system_prompt\n",
    "        role_txt = \"'You are a graduating SHS student, excellent at summarizing notes in layman's terms.\"\n",
    "        \n",
    "        # Saving the transcribed text and summary to default directory\n",
    "        note_taker = OpenAI_NoteTaker(input_dir=\"path/to/input\")\n",
    "        note_taker.take_notes(system_prompt=role_txt)\n",
    "        note_taker.save_notes()\n",
    "        \n",
    "        # Saving the transcribed text and summary to specified directory\n",
    "        note_taker = OpenAI_NoteTaker(input_dir=\"path/to/input\")\n",
    "        note_taker.take_notes(system_prompt=\"summarize the above text in 3 points\")\n",
    "        note_taker.save_notes(export_transcription_dir=\"path/to/export/transcription\", \n",
    "                              export_summary_dir=\"path/to/export/summary\")\n",
    "        \n",
    "        Attributes:\n",
    "        -----------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.Transcriber.save_txt(export_dir=export_transcription_dir)\n",
    "        self.Summarizer.save_txt(export_dir=export_summary_dir)\n",
    "        \n",
    "        \n",
    "    def get_total_job_price(self):\n",
    "        \"\"\"\n",
    "        Calculates the total price of the transcription and summarization job, and prints the breakdown.\n",
    "\n",
    "        Parameters:\n",
    "        None.\n",
    "\n",
    "        Methods:\n",
    "        - OpenAI_Transcriber.get_price(): Calculate the price of the transcription job.\n",
    "        - OpenAI_Summarizer.get_price(): Calculate the price of the summarization job.\n",
    "\n",
    "        Examples:\n",
    "        1. Calculate and print the total price of the job:\n",
    "            note_taker = OpenAI_NoteTaker(input_dir=\"/path/to/input/dir/\",\n",
    "                                          transcriber_model=\"whisper-1\",\n",
    "                                          USD_per_min=0.006,\n",
    "                                          summarizer_model=\"gpt-3.5-turbo\",\n",
    "                                          USD_per_1k=0.002,\n",
    "                                          encoding_name=\"cl100k_base\")\n",
    "            note_taker.take_notes(system_prompt=\"Summarize the text in 5 points.\",\n",
    "                                  n_items=5,\n",
    "                                  show_transcription=False,\n",
    "                                  show_notes=True)\n",
    "            note_taker.get_total_job_price()\n",
    "\n",
    "        Attributes:\n",
    "        - self.transcribed_price (float): The price of the transcription job in USD.\n",
    "        - self.summarization_price (float): The price of the summarization job in USD.\n",
    "        - self.total_job_price (float): The total price of the job in USD.\n",
    "        - self.transcribed_price_dict (dict): A dictionary containing the price of the transcription job.\n",
    "        - self.summarization_price_dict (dict): A dictionary containing the price of the summarization job.\n",
    "        - self.total_job_price_dict (dict): A dictionary containing the total price of the job.\n",
    "        - self.complete_job_price_dict (dict): A dictionary containing the breakdown of the job price.\n",
    "        - self.complete_job_price_dict_USD (dict): A dictionary containing the breakdown of the job price in USD.\n",
    "        \"\"\"\n",
    "        self.Transcriber.get_price()\n",
    "        self.Summarizer.get_price()\n",
    "        \n",
    "        self.transcribed_price = float(self.Transcriber.total_price)\n",
    "        self.summarization_price = float(self.Summarizer.output_price_dict['total_tokens'])\n",
    "        self.total_job_price = self.transcribed_price + self.summarization_price\n",
    "        \n",
    "        self.transcribed_price_dict = {'transcription_price': self.transcribed_price} \n",
    "        self.summarization_price_dict = {'summarization_price': self.summarization_price} \n",
    "        self.total_job_price_dict = {'total_job_price': self.total_job_price}\n",
    "        \n",
    "        self.complete_job_price_dict = self.transcribed_price_dict | self.summarization_price_dict | self.total_job_price_dict\n",
    "        self.complete_job_price_dict_USD = {job_type: f\"{value:.5f} USD\" for job_type, value in self.complete_job_price_dict.items()}\n",
    "        \n",
    "        print('\\nJob Price Breakdown: \\n')\n",
    "        for job_type,value_USD in self.complete_job_price_dict_USD.items(): \n",
    "            print(f\"{job_type}: {value_USD}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763856d",
   "metadata": {},
   "source": [
    "# Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96079f59",
   "metadata": {},
   "source": [
    "## A. Q&A about advise for students who want to pursue a career as a data engineer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d26e3",
   "metadata": {},
   "source": [
    "- Prepare role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de57ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a detail-oriented data science student from the Philippines, who can easily transcribe text to pure English.\n"
     ]
    }
   ],
   "source": [
    "role_txt = \"You are a detail-oriented data science student from the Philippines, who can easily transcribe text to pure English.\"\n",
    "print(role_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c539da",
   "metadata": {},
   "source": [
    "- Apply `OpenAI_NoteTaker` to audio file of my recording to get notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4195b48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size: 5.95 MB.\n",
      "Duration: 390.06 s\n",
      "Input transcription tokens: 1324\n",
      "\n",
      "NoteTaker's Summary in 7 points: \n",
      "\n",
      "- The speaker is asked for advice on how college or graduate students can prepare for a career in data engineering and if Databricks can be part of that preparation.\n",
      "- The speaker believes that it is hard to learn data engineering without working on actual data.\n",
      "- The speaker suggests that internships that expose students to that kind of environment will be helpful.\n",
      "- Attitude and work ethic are important when interviewing for data engineering positions. The drive to learn and having a growth mindset are also emphasized.\n",
      "- There are many paths to becoming a data engineer, as the speaker's experience began with software development before transitioning to data engineering.\n",
      "- To demonstrate skills, the speaker suggests building a portfolio or body of work, preferably as part of a team and focused on solving tough problems.\n",
      "- Databricks offers a university alliance program to invest in the talent of the future, providing resources and learning material to universities that teach Databricks.\n",
      "CPU times: total: 734 ms\n",
      "Wall time: 48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DE_NoteTaker = OpenAI_NoteTaker(input_dir='Data/Input/DE question converted.mp3')\n",
    "\n",
    "DE_NoteTaker.take_notes(system_prompt=role_txt, \n",
    "                        n_items=7, \n",
    "                        show_notes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7d568",
   "metadata": {},
   "source": [
    "- Save raw transcription and summarized notes.\n",
    "- View total pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4647d175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript saved at: Data/Output/QnA_transcribed.txt\n",
      "Summarized note saved at: Data/Output/QnA_summarized.txt\n",
      "\n",
      "Job Price Breakdown: \n",
      "\n",
      "transcription_price: 0.03901 USD\n",
      "summarization_price: 0.00312 USD\n",
      "total_job_price: 0.04213 USD\n"
     ]
    }
   ],
   "source": [
    "DE_NoteTaker.save_notes(export_transcription_dir='Data/Output/QnA_transcribed', \n",
    "                        export_summary_dir='Data/Output/QnA_summarized')\n",
    "\n",
    "DE_NoteTaker.get_total_job_price()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec9fb8",
   "metadata": {},
   "source": [
    "# To do:\n",
    "\n",
    "- Add a separate class called `OpenAI_Interrogator` that creates a chatbot using GPT-3.5 turbo that users can use to discuss about the summarization output.\n",
    "- Add an option for `OpenAI_NoteTaker` to split either the input audio/video file or the output transcription. This will be useful if discussions are lengthy enough, though manual splitting of input files is still recommended.\n",
    "- Make an app out of this repository using [StreamLit](https://docs.streamlit.io/library/get-started).\n",
    "\n",
    "# Final Thoughts\n",
    "\n",
    "- LLM-based projects should be done collaboratively with supplementation in mind, as opposed to total replacement of human input.\n",
    "    - Complementing human skills and knowledge: LLMs are powerful tools for processing and analyzing vast amounts of data, but they lack the intuition, creativity, and domain-specific knowledge that humans possess. Therefore, LLM-based projects should be done collaboratively, with LLMs serving as supplements to human input rather than as complete replacements. This approach ensures that the final output is well-rounded, accurate, and takes into account human insights and expertise.\n",
    "\n",
    "    - Ensuring ethical considerations: While LLMs can be incredibly useful in processing data and generating insights, they can also perpetuate biases or perpetuate ethical concerns if not used responsibly. By working collaboratively, humans can ensure that the input data and resulting outputs are ethical and unbiased. Additionally, they can monitor the performance of the LLM and adjust the input data and processes accordingly.\n",
    "\n",
    "    - Achieving more comprehensive results: LLMs have limitations and may not be able to process all types of data or handle certain tasks. By working collaboratively with humans, LLMs can supplement human efforts and enable the team to achieve more comprehensive results. For instance, while an LLM can process vast amounts of text data, a human can interpret the sentiment or intent behind the text, which may not be possible for the LLM.\n",
    "    \n",
    "\n",
    "- Projects like these should be replicated using different LLMs, with priority for open-source ones.\n",
    "    - Fostering transparency and accountability: Open-source LLMs are often more transparent than proprietary ones, allowing for greater visibility into their inner workings and performance. By prioritizing open-source LLMs, the team can ensure that the project is transparent and accountable to stakeholders. Additionally, open-source LLMs are often developed by a community of researchers and practitioners, who can provide feedback and contribute to the improvement of the models.\n",
    "\n",
    "    - Encouraging innovation and collaboration: Open-source LLMs are typically developed collaboratively by a community of researchers and practitioners. By prioritizing open-source LLMs, the team can contribute to this community and help drive innovation in the field. Additionally, open-source LLMs often have a larger user base and more extensive documentation, making it easier for the team to integrate them into the project and learn from others' experiences.\n",
    "\n",
    "    - Promoting accessibility and affordability: Open-source LLMs are often free to use and distribute, making them more accessible and affordable than proprietary models. By prioritizing open-source LLMs, the team can make the project more accessible to a wider range of users and organizations. Additionally, open-source LLMs can help reduce the overall cost of the project by avoiding licensing fees or proprietary dependencies. This approach can make the project more sustainable in the long run and ensure that it can be scaled and maintained over time.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782d2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

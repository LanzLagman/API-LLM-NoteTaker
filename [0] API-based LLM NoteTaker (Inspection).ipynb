{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7d4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.1\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb5b61",
   "metadata": {},
   "source": [
    "- Import relevant libraries:\n",
    "    - `os`: to interact with the operating system, allowing local file access and manipulation.\n",
    "    - `openai`: to interact with the OpenAI API, allowing the use of language models (LLMs) to generate text, translate languages, summarize text, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ff05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296be97",
   "metadata": {},
   "source": [
    "- Load the `.txt` file that contains your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d24370",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/Input/api-key.txt', 'r') as file:\n",
    "    api_key = file.read()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d6030",
   "metadata": {},
   "source": [
    "# Part I: Explore how the APIs work\n",
    "\n",
    "- In order to create our NoteTaker using OpenAI's APIs, we must first learn how the [speech-to-text](https://platform.openai.com/docs/guides/speech-to-text) and [chat completion](https://platform.openai.com/docs/guides/chat) APIs work.\n",
    "- The main objective is to use OpenAI APIs in order to summarize the recorded audio file of my question to the Databricks: Destination Lakehouse Pilipinas, about how students should prepare for a Data Engineering role while still in school."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a126b68",
   "metadata": {},
   "source": [
    "## A. Audio transcription via [OpenAI Whisper](https://openai.com/research/whisper) API\n",
    "\n",
    "- Whisper is an Automatic Speech Recognition (ASR) system that has been trained on a large and diverse dataset consisting of 680,000 hours of multilingual and multitask supervised data from the web.\n",
    "- The Whisper architecture is implemented as an encoder-decoder Transformer that can perform tasks such as language identification, phrase-level timestamps, multilingual speech transcription, and to-English speech translation.\n",
    "- Whisper's zero-shot performance across many diverse datasets is much more robust and makes 50% fewer errors than other existing approaches that use smaller, more closely paired audio-text training datasets or unsupervised audio pretraining.\n",
    "- Whisper's approach of alternating between transcribing in the original language and translating to English is particularly effective at learning speech-to-text translation and outperforms the supervised state-of-the-art on CoVoST2 to English translation zero-shot.\n",
    "\n",
    "\n",
    "**Price:** around 0.006 USD per minute.\n",
    "\n",
    "**Filesize Limit:** <25 MB\n",
    "\n",
    "For more details, please check the [paper](https://cdn.openai.com/papers/whisper.pdf), [model card](https://github.com/openai/whisper/blob/main/model-card.md), and [code](https://github.com/openai/whisper)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21415573",
   "metadata": {},
   "source": [
    "### Sample syntax using Whisper\n",
    "\n",
    "- Define an `fpath` string variable, for the file destination of your audio or video file to be transcribed.\n",
    "- Create a new variable `audio_file` using the native Python [`open()`](https://docs.python.org/3/library/functions.html#open) function with `\"rb\"` as an argument for\n",
    "    - `'r'`: open for reading (default)\n",
    "    - `'b'`: binary mode\n",
    "- Lastly, define a variable `transcript` using the `transcribe()` function of `openai.Audio`, with `\"whisper-1\"` for the string argument declaring that we will use the Whisper-1 model, then `audio_file`.\n",
    "    - `openai.Audio` is the OpenAI API module that provides methods for working with audio files, including transcription of speech-to-text using the Whisper API.\n",
    "- **Note:** While not covered in our discussion, prompting in OpenAI's GPT models allows users to provide initial text as input to guide the model's generation of new text, but this is not a required feature for using the OpenAI API. **This should be considered and prioritized when working upon this project for improvement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b942589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpath = 'Data/Input/DE question converted.mp3'\n",
    "\n",
    "audio_file = open(fpath, \"rb\")\n",
    "\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7277df",
   "metadata": {},
   "source": [
    "- Preview `transcript`, the `OpenAIObject` that contains a JSON file. \n",
    "- The JSON contains the text of the transcript as a string along with other metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00000599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x2236bfa65e0> JSON: {\n",
       "  \"text\": \"My question would be, what advice can you give to a college student or a graduate student who wants to pursue a career as a data engineer? How should he-she prepare in order to have the adequate skill sets that would enable an easy transition from the academic to the industry? And can Databricks be part of that preparation? Thank you. So, I just want to repeat the question to answer. I think the question was from the University of the Philippines, right, is what I heard. And I think the question is around what advice would we give to students, right, entering into kind of the space? And then number two, what support can Databricks provide, right? Is that correct? Ah, yes. How could Databricks be part of the preparation if someone... Okay, so I can take the second one. You want to cover all of them. First of all, would you advise me to, you know, someone studying at university today but entering into the state NAL, what advice would you be giving them if that's the journey they want to go on? So thanks for the question. I think it's a good but very tricky question also. I feel like there are so many online resources that you can look up already, YouTube, I know there's a Databricks Academy, and there's so much documentation you can read up. I think the very tricky part is it's very hard, especially for data engineering, it's hard to learn data engineering when you're not working with actual data. I know there are a lot of data sets on the internet that you can use and play around with, but without an actual business case that really provides business value, that's really driving the urgency. Honestly, for me, it's never where I just start a side project and then learn from it. I've always learned best because there's some kind of business value that I'm trying to work for, trying to generate, and almost always I've gotten that experience in the context of working on a project or a company. So maybe one piece of advice I would give is if you could look for internships that would expose you to that kind of environment, I think would be one of the most helpful ways to learn. Obviously, you spending the time yourself to study online resources would definitely give you an edge to get those internship opportunities or job opportunities even right out of graduating. Just to add, we're in a time actually that you can learn anything. There are a lot of resources online that you can take note of, but we're also in a time that you can be distracted by a lot of things. So it all comes down to, that's the way I see it. When I ask people, when I interview restaurants, I always check on, okay, number one, attitude. What's the work ethic? There has to be a drive to learn. That's one. There's a good growth mindset because as I mentioned a while ago, skills can be learned, but attitude, the character, that's a different business. Totally different. So second is there's a lot of path that you can take to be a data engineer, but again, an example from my case, my career is more on software development first and then I went through DevOps kind of thing, infrastructure, scalability. So those kind of things, you can make use, like your foundation also to become a data engineer. But it's also hard. As I mentioned, it's not hard. For example, if you're going to be a fresh grad, you will be working with actual data right away. So it all comes down to, I actually hired someone from UP last year who is very good in data science as a data engineer because the work ethic is there. So it's all comes down to two things. So learn how to break things, learn from it, apply it as much as you can, and continue growing. There's a lot of YouTube channels as well that have data engineering, what do you call that, maps, skills map that you can check in the Internet. So yeah, it's an interesting time to be in. A lot of things you can learn if you want to. Yeah. I'll build on what both of the panelists have said. Look, there's a huge amount of collateral out on the web that you can consume, probably more than you could ever consume in a lifetime. I think it's about being really, really focused. And I think the focus that you need to bring is around what is my body of work. Because there's a lot of people that will say, hey, I've gone and done a course, I've gone and done a search, I've gone and done this, but where's the evidence that you've applied that? So my advice would be build a portfolio, build a body of work, and you can't do that in the absence of being in the work environment. One of the best ways is cackles. These data science and data engineering competitions. Find like-minded individuals, come together and go and solve tough problems using open data sets together, and then do it in the team sport-like manner that these companies require. Because the other thing is around how you work as a team player. There's a lot of individuals that are really, really good at football. You don't want that. You want a team player. You want someone that's going to be fantastic, who culturally, first and foremost, is able to work in a team to solve tough problems. So I'd say build a portfolio of work, demonstrate that you can do that in a team-like manner, demonstrate that you can solve tough problems, leverage all of the material that's out there. Databricks has a phenomenal amount of open, free learning. If you've not seen it, just go to our learning and enablement site. There's a huge amount there. We're running training pretty much any day of the given week, so check it out. And then specifically for the University of the Philippines, and I'd say this to the university, but I'd say this to all of our corporate customers and prospects, we want to know who you're working with from an academic faculty relationship perspective. That's important to us. We have an alliance program around universities. So if there's universities, academic relationships, or faculty members that you have, let us know, because we want to build and invest in the talent of the future. So we do have a university alliance program. We provide resources, labs, learning material to those universities to go and run and train people on Databricks. So we're kind of connected back to the universities and the talent of the future. Cool. Lovely question. Love that. That's awesome. Thank you.\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e060220",
   "metadata": {},
   "source": [
    "- Preview the `text` item from `transcript`.\n",
    "- This is the most relevant component of `transcript`, so it's better to save it to a variable called `transcript_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9b0a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My question would be, what advice can you give to a college student or a graduate student who wants to pursue a career as a data engineer? How should he-she prepare in order to have the adequate skill sets that would enable an easy transition from the academic to the industry? And can Databricks be part of that preparation? Thank you. So, I just want to repeat the question to answer. I think the question was from the University of the Philippines, right, is what I heard. And I think the question is around what advice would we give to students, right, entering into kind of the space? And then number two, what support can Databricks provide, right? Is that correct? Ah, yes. How could Databricks be part of the preparation if someone... Okay, so I can take the second one. You want to cover all of them. First of all, would you advise me to, you know, someone studying at university today but entering into the state NAL, what advice would you be giving them if that's the journey they want to go on? So thanks for the question. I think it's a good but very tricky question also. I feel like there are so many online resources that you can look up already, YouTube, I know there's a Databricks Academy, and there's so much documentation you can read up. I think the very tricky part is it's very hard, especially for data engineering, it's hard to learn data engineering when you're not working with actual data. I know there are a lot of data sets on the internet that you can use and play around with, but without an actual business case that really provides business value, that's really driving the urgency. Honestly, for me, it's never where I just start a side project and then learn from it. I've always learned best because there's some kind of business value that I'm trying to work for, trying to generate, and almost always I've gotten that experience in the context of working on a project or a company. So maybe one piece of advice I would give is if you could look for internships that would expose you to that kind of environment, I think would be one of the most helpful ways to learn. Obviously, you spending the time yourself to study online resources would definitely give you an edge to get those internship opportunities or job opportunities even right out of graduating. Just to add, we're in a time actually that you can learn anything. There are a lot of resources online that you can take note of, but we're also in a time that you can be distracted by a lot of things. So it all comes down to, that's the way I see it. When I ask people, when I interview restaurants, I always check on, okay, number one, attitude. What's the work ethic? There has to be a drive to learn. That's one. There's a good growth mindset because as I mentioned a while ago, skills can be learned, but attitude, the character, that's a different business. Totally different. So second is there's a lot of path that you can take to be a data engineer, but again, an example from my case, my career is more on software development first and then I went through DevOps kind of thing, infrastructure, scalability. So those kind of things, you can make use, like your foundation also to become a data engineer. But it's also hard. As I mentioned, it's not hard. For example, if you're going to be a fresh grad, you will be working with actual data right away. So it all comes down to, I actually hired someone from UP last year who is very good in data science as a data engineer because the work ethic is there. So it's all comes down to two things. So learn how to break things, learn from it, apply it as much as you can, and continue growing. There's a lot of YouTube channels as well that have data engineering, what do you call that, maps, skills map that you can check in the Internet. So yeah, it's an interesting time to be in. A lot of things you can learn if you want to. Yeah. I'll build on what both of the panelists have said. Look, there's a huge amount of collateral out on the web that you can consume, probably more than you could ever consume in a lifetime. I think it's about being really, really focused. And I think the focus that you need to bring is around what is my body of work. Because there's a lot of people that will say, hey, I've gone and done a course, I've gone and done a search, I've gone and done this, but where's the evidence that you've applied that? So my advice would be build a portfolio, build a body of work, and you can't do that in the absence of being in the work environment. One of the best ways is cackles. These data science and data engineering competitions. Find like-minded individuals, come together and go and solve tough problems using open data sets together, and then do it in the team sport-like manner that these companies require. Because the other thing is around how you work as a team player. There's a lot of individuals that are really, really good at football. You don't want that. You want a team player. You want someone that's going to be fantastic, who culturally, first and foremost, is able to work in a team to solve tough problems. So I'd say build a portfolio of work, demonstrate that you can do that in a team-like manner, demonstrate that you can solve tough problems, leverage all of the material that's out there. Databricks has a phenomenal amount of open, free learning. If you've not seen it, just go to our learning and enablement site. There's a huge amount there. We're running training pretty much any day of the given week, so check it out. And then specifically for the University of the Philippines, and I'd say this to the university, but I'd say this to all of our corporate customers and prospects, we want to know who you're working with from an academic faculty relationship perspective. That's important to us. We have an alliance program around universities. So if there's universities, academic relationships, or faculty members that you have, let us know, because we want to build and invest in the talent of the future. So we do have a university alliance program. We provide resources, labs, learning material to those universities to go and run and train people on Databricks. So we're kind of connected back to the universities and the talent of the future. Cool. Lovely question. Love that. That's awesome. Thank you.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_text = transcript['text']\n",
    "transcript_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f15d5a",
   "metadata": {},
   "source": [
    "## Audio transcription via Whisper library\n",
    "\n",
    "- One alternative reason to use the whisper library instead of using the OpenAI API in order to access the whisper so that [you don't have to pay for using the OpenAI API](https://github.com/openai/whisper/discussions/1088).\n",
    "- The downside however, is it will take more time to transcribe and translate since this approach uses your own local machine. \n",
    "- Overall, I recommend the use of the API if the audio and video to be transcribed is for an open-source project and does not contain sensitive information.\n",
    "\n",
    "### Some points to consider:\n",
    "\n",
    "- It is a self-contained library that can be run locally without requiring an internet connection, whereas the OpenAI API requires an internet connection to use.\n",
    "- The library option provides more control over the training process and allows for more fine-tuned models than the OpenAI API, but requires more technical expertise to use effectively.\n",
    "- Allows for modification and customization to meet specific needs, whereas the OpenAI API is a closed system with limited options. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3993f",
   "metadata": {},
   "source": [
    "### Installation via Jupyter notebook\n",
    "\n",
    "- The raw-nbconvert cells below must be converted into code cells in order for the installation to be run.\n",
    "- install [ffmpeg-python](https://github.com/kkroening/ffmpeg-python), one of the possible prerequisites.\n",
    "- install whisper from the GitHub repo."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a0a17c2",
   "metadata": {},
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a8296ae",
   "metadata": {},
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf4fd3",
   "metadata": {},
   "source": [
    "### Sample syntax using the Whisper library\n",
    "\n",
    "- import `whisper`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd4670de",
   "metadata": {},
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f2028",
   "metadata": {},
   "source": [
    "- Define and load the base `model`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7bf925b",
   "metadata": {},
   "source": [
    "%%time\n",
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591b982",
   "metadata": {},
   "source": [
    "- Define `fpath` and transcribe using the base `model` to produce `result`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "62190a11",
   "metadata": {},
   "source": [
    "fpath = 'Data/Input/DE question converted.mp3'\n",
    "result = model.transcribe(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40f1f4",
   "metadata": {},
   "source": [
    "- Preview transcription."
   ]
  },
  {
   "cell_type": "raw",
   "id": "66205bac",
   "metadata": {},
   "source": [
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c9d9b6",
   "metadata": {},
   "source": [
    "### Some notes:\n",
    "\n",
    "- Whisper uses an ensemble of models to generate transcriptions, which means that different models are used for different runs, leading to variations in the output.\n",
    "\n",
    "- The models used by Whisper are probabilistic, meaning that they rely on chance to produce transcriptions. Therefore, the output may vary even if the input is the same.\n",
    "\n",
    "- Whisper uses a random seed to initialize the models, which may cause variations in the output between different runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb58bd",
   "metadata": {},
   "source": [
    "## B. Summarizing text with gpt-3.5-turbo\n",
    "\n",
    "- Now that we have `transcript_text`, we want to summarize it into seven points using OpenAI's Chat Completion with `gpt-3.5-turbo` as the model.\n",
    "\n",
    "- According to OpenAI, GPT-3.5 models can understand and generate natural language or code. The most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat but works well for traditional completions tasks as well.\n",
    "\n",
    "- One of the key benefits of using the GPT3.5 Turbo API for chat completion is its ability to learn from the inputs that it receives. As the API is used to generate responses to different prompts, it will gradually develop a better understanding of language and become better at generating accurate and appropriate responses.\n",
    "\n",
    "- Some points to consider:\n",
    "    - `openai.ChatCompletion.create()` contains two variables: `model` and `messages`.\n",
    "    - `model` specifies the OpenAI LLM used. For now, we prefer `\"gpt-3.5-turbo\"` for completion tasks.\n",
    "    - `messages` contains the list of dictionaries:\n",
    "        - `\"system\"`: sets the behavior of the `\"assistant\"`, defining the **role** that the model takes, as if it is the persona.\n",
    "        - `\"user\"`: refers to the text of the message entered by the user. \n",
    "        - `\"assistant\"`: refers to the text of the message generated by the AI-based assistant.\n",
    "    - For both `\"system\"` and `\"user\"`, it is important to carefully engineer the prompts to ensure that they are clear, concise, and relevant to the task at hand.\n",
    "    \n",
    "**Price:** USD 0.002 per 1k tokens.\n",
    "\n",
    "**Token Limit:** <4096 tokens. (1 token $\\approx$ 0.75 of a word)\n",
    "\n",
    "For more details, please check the [model index](https://platform.openai.com/docs/models/gpt-3-5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b735e3",
   "metadata": {},
   "source": [
    "### Prompt Engineering Preparation\n",
    "\n",
    "- Define `role_txt` for `\"system\"`:\n",
    "    - This is \"persona\" that we want `\"gpt-3.5-turbo\"` model to take. \n",
    "    - When defining this persona, it is important to consider a concise prompt that humanizes this persona.\n",
    "    - A suggestion would be to provide a general role, preceded by a background then followed by some relevant context regarding what the model is tasked to do.\n",
    " - `\"user\"` prompt:\n",
    "     - Since our objective is to summarize the given `transcript_text` output into several points, a simple command would suffice. \n",
    "     - For now, we could say we want `transcript_text` to be summarized into seven points, but next time, this should be a variable integer parameter.\n",
    "     - Next, the whole prompt should be in the form of an f-string containing `transcript_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "518f3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_txt = \"You are a detail-oriented data science student from the Philippines, great with transcribing text to pure English.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b70ccb",
   "metadata": {},
   "source": [
    "### Chat Completion Syntax\n",
    "\n",
    "- Let's generate `response` using `role_txt`, and `transcript_text` previously generated using Whisper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58eead51",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \n",
    "         \"content\": role_txt},\n",
    "        \n",
    "        {\"role\":\"user\", \n",
    "         \"content\": f\"Summarize the following transcript into 7 key bullet points: '\\n{transcript_text}'\"}\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5801cd1c",
   "metadata": {},
   "source": [
    "- Let's inspect the `response` output.\n",
    "- We can see that the important components of `response` are the following:\n",
    "    - The `\"content\"` attribute under the message dictionary is the most important since it contains the actual result or the response generated by the GPT-3.5 Turbo API to the prompt provided. In this case, the response is a summary of the given transcript in seven key bullet points. This is the main output that we must consider, and should be saved as a text file later.\n",
    "\n",
    "    - The `\"usage\"` dictionary contains information on the number of tokens used in the completion process, including the prompt and response. This information is important because it can be used to track the cost of using the GPT-3.5 Turbo API, as it charges based on the number of tokens used. Knowing this information can help manage the usage and cost of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b2a6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-768SNCwVWruD2KM28Ab3VhPUP4LO3 at 0x2236bf184f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"1. The question is about advice for preparing to pursue a career as a data engineer. \\n2. There are many online resources available, but it's hard to learn data engineering without working with actual data. \\n3. One advice is to look for internships that would expose you to that kind of environment. \\n4. Attitude, work ethic, and a growth mindset are important when pursuing a career as a data engineer. \\n5. Building a portfolio of work and demonstrating the ability to solve tough problems in a team-like manner is essential. \\n6. Databricks has a significant amount of open and free learning resources for anyone interested. \\n7. Databricks has a university alliance program that provides resources, labs, and learning material to universities to train people on Databricks.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681696831,\n",
       "  \"id\": \"chatcmpl-768SNCwVWruD2KM28Ab3VhPUP4LO3\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 161,\n",
       "    \"prompt_tokens\": 1438,\n",
       "    \"total_tokens\": 1599\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02595f",
   "metadata": {},
   "source": [
    "- To pretty print the prompt output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff35326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The question is about advice for preparing to pursue a career as a data engineer. \n",
      "2. There are many online resources available, but it's hard to learn data engineering without working with actual data. \n",
      "3. One advice is to look for internships that would expose you to that kind of environment. \n",
      "4. Attitude, work ethic, and a growth mindset are important when pursuing a career as a data engineer. \n",
      "5. Building a portfolio of work and demonstrating the ability to solve tough problems in a team-like manner is essential. \n",
      "6. Databricks has a significant amount of open and free learning resources for anyone interested. \n",
      "7. Databricks has a university alliance program that provides resources, labs, and learning material to universities to train people on Databricks.\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642069b8",
   "metadata": {},
   "source": [
    "- Define `usage_dict` as the dictionary of tokens from `response`, which contains the following:\n",
    "    - `prompt_tokens`: the number of tokens in the prompt, which is the input given to the model.\n",
    "    - `completion_tokens`: the number of tokens in the generated completion, which is the output generated by the model based on the prompt.\n",
    "    - `total_tokens`: the total number of tokens used by the model to generate the completion, which is the sum of the prompt and completion tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06181692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 1438, 'completion_tokens': 161, 'total_tokens': 1599}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage_dict = dict(response['usage'])\n",
    "usage_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f1ede",
   "metadata": {},
   "source": [
    "- Currently, the [price of GPT 3.5 tokens](https://openai.com/pricing) is 0.002 USD per 1000 tokens.\n",
    "- It is useful therefore to define `price_dict`, which multiplies this factor to the token values of `usage_dict` in order to obtain the job price of the chat completion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d88afeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 0.002876,\n",
       " 'completion_tokens': 0.00032199999999999997,\n",
       " 'total_tokens': 0.003198}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_dict = {k: v*(0.002/1000.0) for (k, v) in usage_dict.items()}\n",
    "price_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a2b7a",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "Based on our exploration, in order to create our NoteTaker using OpenAI APIs, a recommended approach would be:\n",
    "- Create an `OpenAI_Transcriber` class that uses the Whisper API, and can do the following:\n",
    "    - Convert input video to audio, in order to save memory.\n",
    "    - Get filesize and duration of input file.\n",
    "    - Get estimated transcription price.\n",
    "    - Transcription using `openai.Audio.transcribe()`\n",
    "    - Save transcription output as `.txt` file.\n",
    "- Create an `OpenAI_Summarizer` class that uses the Chat Completion API, and can do the following:\n",
    "    - Compute input tokens from input transcript.\n",
    "    - Summarize transcript using `openai.ChatCompletion.create()`\n",
    "    - Save output summary as `.txt` file.\n",
    "    - Produce a dictionary like `usage_dict` to indicate summarization cost.\n",
    "    - Compute output tokens from output summary.\n",
    "- Generally, for any input audio/video file received by `OpenAI_Transcriber`, its output transcription will be received by `OpenAI_Summarizer` in order to produce the summary text file.\n",
    "    - Taking into consideration the limits, the input file should be less than 25 MB and the transcription should have less than 4096 tokens.\n",
    "\n",
    "**These will be done on the next part.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988b7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

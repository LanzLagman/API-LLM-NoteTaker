{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7d4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.1\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ff05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296be97",
   "metadata": {},
   "source": [
    "- Load the `.txt` file that contains your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c57d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/Input/api-key.txt', 'r') as file:\n",
    "    api_key = file.read()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d6030",
   "metadata": {},
   "source": [
    "# Part II: Parent Classes\n",
    "\n",
    "- From the first part, we'll proceed with creating the Python classes `OpenAI_Transcriber` and `OpenAI_Summarizer`, which utilizes the speech-to-text (Whisper-1) and chat completion (GPT 3.5 turbo) respectively.\n",
    "- Using a class-based approach for maximizing OpenAI APIs usage provides organization, modularity, and flexibility in implementing media transcription and summarization tasks, which go hand-in-hand in note-taking.\n",
    "- For a usual note-taking routine, these classes are to be used consecutively. \n",
    "- Later, these classes will serve as the parent classes for `OpenAI_NoteTaker` so that the whole note-taking routine will be further streamlined.\n",
    "- ChatGPT has been extensively used for assistance in creating docstrings for each functions, making documentation much easier and bearable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076cb11e",
   "metadata": {},
   "source": [
    "## A. `OpenAI_Transcriber`\n",
    "\n",
    "Recall that we have previously stated that `OpenAI_Transcriber` must have the following functions:\n",
    "- Convert input video to audio, in order to save memory.\n",
    "- Get filesize and duration of input file.\n",
    "- Get estimated transcription price.\n",
    "- Transcription using `openai.Audio.transcribe()`\n",
    "- Save transcription output as `.txt` file.\n",
    " \n",
    "### Methods\n",
    "\n",
    "In response, we have created the following functions, with ease-of-use and cost tracking in mind:\n",
    " \n",
    "- `__init__`: Initializes an instance of the `OpenAI_Transcriber` class with strings from input directory, model name, and price per minute, as stated from [OpenAI's pricing website](https://openai.com/pricing). The `self.filetype` attribute is determined using the [`magic`](https://pypi.org/project/python-magic/) library, which helps to identify the type of file without relying solely on the file extension. This is important because sometimes the file extension may not be accurate, or may be missing altogether. Using magic helps to ensure that the file is correctly identified, which is crucial for subsequent processing steps.\n",
    "\n",
    "- `to_mp3`: Uses a try-except block to handle any exceptions that might occur during the conversion process. Within the try block, it first checks if the input file is already in MP3 format and simply returns the input file if it is. If not, it checks if the input file is in a supported format (e.g., WAV, FLAC) and uses Pydub's `AudioSegment` class to load the input audio file. It then applies Pydub's `export()` method to convert the audio to MP3 format. If the input file is not in a supported format, the function raises a ValueError with a corresponding message. Finally, the function returns the output MP3 file.\n",
    "\n",
    "\n",
    "To install both `pydub` and `magic` in this notebook, simply convert the raw-nbconvert cell below into a code block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af647f4",
   "metadata": {},
   "source": [
    "- Install `pydub` and `python-magic`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "48ebc2ce",
   "metadata": {},
   "source": [
    "!pip install pydub python-magic-bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90963b29",
   "metadata": {},
   "source": [
    "- `get_filesize()`: Returns the size of the input file in bytes, providing users with an estimate of the transcription cost.\n",
    "\n",
    "- `get_duration()`: Returns the duration of the input file in seconds, which is used in conjunction with the transcription price per minute to calculate the estimated cost.\n",
    "\n",
    "- `get_price()`: Calculates the estimated transcription cost based on the duration of the input file and the price per minute charged by OpenAI.\n",
    "\n",
    "- `transcribe_audio()`: Uses the `openai.Audio.transcribe()` method to transcribe the input audio file using the specified OpenAI API key and model, returning the resulting text as a string.\n",
    "\n",
    "- `save_txt()`: Saves the transcribed text to a `.txt` file, allowing for easy access and future use for editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58ccebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import magic\n",
    "from pydub import AudioSegment\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "456ac7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import magic\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "\n",
    "class OpenAI_Transcriber:\n",
    "    \"\"\"\n",
    "    This class provides methods for transcribing an audio file using OpenAI's\n",
    "    transcription service. The class supports automatic conversion of input files\n",
    "    to MP3 format, retrieval of file size and duration, estimation of the cost\n",
    "    of transcription, transcription of the audio file, and saving the transcript\n",
    "    to a text file.\n",
    "    \n",
    "    -----------\n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - input_dir (str): The file path to the audio file to be transcribed.\n",
    "    - transcriber_model (str): The name of the transcriber model to use. Defaults to \"whisper-1\".\n",
    "    - USD_per_min (float): The cost per minute in USD for using the transcriber service. Defaults to 0.006.\n",
    "    \n",
    "    --------\n",
    "    Methods:\n",
    "    --------\n",
    "    \n",
    "    - to_mp3(export_dir=None): Converts the input audio file to MP3 format if necessary.\n",
    "    - get_filesize(): Returns the file size of the input audio file in megabytes.\n",
    "    - get_duration(): Returns the duration of the input audio file in seconds.\n",
    "    - get_price(): Calculates the total price of the transcription service based on the duration of the input audio file.\n",
    "    - transcribe_audio(show_output=False): Transcribes the input audio file using the specified transcriber model.\n",
    "    - save_txt(export_dir=None): Saves the transcription output to a text file.\n",
    "    \n",
    "    -----------\n",
    "    Attributes:\n",
    "    -----------\n",
    "    \n",
    "    - input_dir (str): The file path to the input audio file.\n",
    "    - transcriber_model (str): The name of the transcriber model used.\n",
    "    - USD_per_min (float): The cost per minute in USD for using the transcriber service.\n",
    "    - filepath_mp3 (str): The file path to the MP3 version of the input audio file.\n",
    "    - input_filesize (float): The file size of the input audio file in megabytes.\n",
    "    - duration (float): The duration of the input audio file in seconds.\n",
    "    - transcript (dict): The output of the transcription service, including the transcription text and confidence score.\n",
    "    - transcript_text (str): The transcription text output only.\n",
    "    - filepath_txt (str): The file path to the saved text file containing the transcription output.\n",
    "    \n",
    "    ---------\n",
    "    Examples:\n",
    "    ---------\n",
    "    \n",
    "    # Create an instance of the OpenAI_Transcriber class\n",
    "    transcriber = OpenAI_Transcriber(input_dir=\"audio_file.wav\")\n",
    "    \n",
    "    # Convert the input file to MP3 format\n",
    "    transcriber.to_mp3()\n",
    "    \n",
    "    # Get the duration of the input file\n",
    "    transcriber.get_duration()\n",
    "    \n",
    "    # Get the price of the transcription service\n",
    "    transcriber.get_price()\n",
    "    \n",
    "    # Transcribe the input file\n",
    "    transcriber.transcribe_audio()\n",
    "    \n",
    "    # Save the transcription output to a text file\n",
    "    transcriber.save_txt()\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_dir:str, \n",
    "                 transcriber_model:str = \"whisper-1\", \n",
    "                 USD_per_min:float = 0.006):\n",
    "        \"\"\"\n",
    "        Initializes the OpenAI_Transcriber class.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        input_dir: str\n",
    "            The directory path of the input audio file.\n",
    "        transcriber_model: str, optional (default=\"whisper-1\")\n",
    "            The OpenAI transcriber model to use. Default is \"whisper-1\".\n",
    "        USD_per_min: float, optional (default=0.006)\n",
    "            The price per minute for transcribing audio. Default is 0.006 USD per minute.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.input_dir = input_dir\n",
    "        self.transcriber_model = transcriber_model\n",
    "        self.USD_per_min = USD_per_min\n",
    "        \n",
    "        self.audio_file = open(self.input_dir, \"rb\")\n",
    "        self.filetype = magic.Magic(mime=True).from_file(self.input_dir)\n",
    "        \n",
    "    def to_mp3(self, export_dir=None):\n",
    "        \"\"\"\n",
    "        Convert the input audio file to MP3 format using ffmpeg.\n",
    "\n",
    "        Args:\n",
    "            export_dir (str, optional): If specified, the path to save the MP3 file.\n",
    "                                        If None, the MP3 file is saved in the same directory\n",
    "                                        as the input file with the same name but with .mp3 extension.\n",
    "                                        Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Raises:\n",
    "            Exception: Raised if an error occurs during the conversion process.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.filetype == \"audio/mpeg\":\n",
    "            print(\"File is already in mp3 format.\")\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                self.audiosegment = AudioSegment.from_file(self.input_dir, self.filetype.split('/')[1])\n",
    "        \n",
    "                if export_dir==None:\n",
    "                    self.filepath_mp3 = self.input_dir.replace(self.input_dir.split('.')[-1],'mp3')\n",
    "                    self.audiosegment.export(self.filepath_mp3, format=\"mp3\")\n",
    "\n",
    "                else:\n",
    "                    self.filepath_mp3 = export_dir\n",
    "                    self.audiosegment.export(self.filepath_mp3, format=\"mp3\")\n",
    "\n",
    "                self.audio_file = open(self.filepath_mp3, \"rb\")\n",
    "                self.filetype = magic.Magic(mime=True).from_file(self.filepath_mp3)\n",
    "                \n",
    "                print(f\"Output .mp3 file saved to {self.filepath_mp3}\")\n",
    "                print(\"Conversion to mp3 successful.\")\n",
    "                \n",
    "                self.input_dir = self.filepath_mp3\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(\"Error converting file to mp3.\")\n",
    "                print(e)\n",
    "        \n",
    "                \n",
    "    def get_filesize(self):\n",
    "        \"\"\"\n",
    "        Get the file size of the input audio file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \n",
    "        Prints\n",
    "        ------\n",
    "        input_filesize : float\n",
    "            The size of the input audio file in MB.\n",
    "        \"\"\"\n",
    "        self.input_filesize = os.stat(self.input_dir).st_size / (1024 * 1024)\n",
    "        print(f\"Input file size: {self.input_filesize:.2} MB.\")\n",
    "        \n",
    "            \n",
    "    def get_duration(self):\n",
    "        \"\"\"\n",
    "        Gets the duration of the input audio file.\n",
    "        \n",
    "        Raises:\n",
    "            OSError: If the file cannot be opened or read.\n",
    "            TypeError: If the file type is not supported.\n",
    "        \n",
    "        Prints:\n",
    "            The duration of the audio file in seconds.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.filetype == \"audio/wav\" or self.filetype == \"audio/x-wav\":\n",
    "                with wave.open(self.input_dir, 'r') as f:\n",
    "                    frames = f.getnframes()\n",
    "                    rate = f.getframerate()\n",
    "                    self.duration = frames / float(rate)\n",
    "                    print(f'Duration: {self.duration:.2} s')\n",
    "            else:\n",
    "                audio = AudioSegment.from_file(self.input_dir)\n",
    "                self.duration = audio.duration_seconds\n",
    "                print(f'Duration: {self.duration:.2} s')\n",
    "                \n",
    "        except:\n",
    "            print(\"Error getting file length.\")\n",
    "    \n",
    "    def get_price(self):\n",
    "        \"\"\"\n",
    "        Calculates the total cost of transcribing the audio based on its duration and the given USD per minute rate.\n",
    "\n",
    "        Raises:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.total_price = self.duration * (self.USD_per_min/60.0)\n",
    "        \n",
    "    def transcribe_audio(self, \n",
    "                         show_output=False):\n",
    "        \"\"\"\n",
    "        Transcribes the audio file using the specified transcriber model.\n",
    "\n",
    "        Args:\n",
    "            show_output (bool, optional): If True, prints the transcribed text. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.transcript = openai.Audio.transcribe(self.transcriber_model, \n",
    "                                                  self.audio_file)\n",
    "        \n",
    "        self.transcript_text = self.transcript['text']\n",
    "        \n",
    "        if show_output==True:\n",
    "            print(self.transcript_text)\n",
    "            \n",
    "    def save_txt(self, export_dir=None): \n",
    "        \"\"\"\n",
    "        Saves the transcript text to a text file.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        export_dir: str, optional\n",
    "            The export directory of the output .txt file. If None, \n",
    "            the directory will be the same as the input audio file.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if export_dir is None:\n",
    "            self.filepath_txt = self.input_dir.replace(self.input_dir.split('.')[-1],' txt')\n",
    "        else:\n",
    "            self.filepath_txt = f\"{export_dir}.txt\"\n",
    "        \n",
    "        with open(self.filepath_txt, 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(self.transcript_text)\n",
    "            f.close()\n",
    "        \n",
    "        print(f\"Transcript saved at: {self.filepath_txt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1c06ed",
   "metadata": {},
   "source": [
    "### Demonstration\n",
    "\n",
    "- Define a variable `test_mp3`, an `OpenAI_Transcriber` object to initialize transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98154448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'audio/mpeg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mp3 = OpenAI_Transcriber('Data/Input/DE question converted.mp3')\n",
    "test_mp3.filetype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158550a5",
   "metadata": {},
   "source": [
    "- Check filesize. Ideally, this should be <25 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7122d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size: 6.0 MB.\n"
     ]
    }
   ],
   "source": [
    "test_mp3.get_filesize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499037f",
   "metadata": {},
   "source": [
    "- Get duration and price, but print the value of the latter to the nearest cent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3efda1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 3.9e+02 s\n",
      "Total Transcription Price: 0.039 USD\n"
     ]
    }
   ],
   "source": [
    "test_mp3.get_duration()\n",
    "test_mp3.get_price()\n",
    "\n",
    "print(f\"Total Transcription Price: {test_mp3.total_price:.2} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a04fc7",
   "metadata": {},
   "source": [
    "- Run the transcription then preview the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a71040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question would be what advice can you give to a college student or a graduate student who wants to pursue a career as a data engineer? How should he she prepare in order to have the adequate skillsets that would enable an easy transition from the academic to the industry? And can data bricks be part of that preparation? Thank you. So, I just want to repeat the question that we got. I think the question was from the University of the Philippines, right? Is what I heard. And I think the question is around what advice would we give to students, right? Entering into kind of the space and then number two, what support can Databricks provide, right? Is that correct? Ah yes, how could Databricks be part of the preparation if someone... I can take the second one. You want to cover all of them first? What would you advise me to someone studying at university today but entering into the state NAL, what advice would you be giving them if that's the journey they want to go on? So, thanks for the question. I think it's a good but very tricky question also. I feel like there's so many online resources that you can look up already. YouTube, I know there's a database academy and there's so much documentation you can read up. I think the very tricky part is it's very hard, especially for data engineering. It's hard to learn data engineering when you're not working with actual data. I know there are a lot of data sets on the internet that you can use and play around with but without an actual business case that really provides business value that's really driving the urgency. Honestly, for me, it's never where I just start a side project and then learn from it. I've always learned best because there's some kind of business value that I'm trying to work for, trying to generate. Almost always, I've gotten that experience in the context of working on a project or a company. Maybe one piece of advice I would give is if you could look for internships that would expose you to that kind of environment, I think would be one of the most helpful ways to learn. Obviously, you spending the time yourself to study online resources would definitely give you an edge to get those internship opportunities or job opportunities even right out of graduating. Just to add, we're in a time actually that you can learn anything. There are a lot of resources online that you can take note of. But we're also in a time that you can be distracted by a lot of things. It all comes down to, that's the way I see it. When I ask people, when I interview restaurants, I always check on, number one, attitude. What's the work ethic? There has to be a drive to learn. There's a good growth mindset because as I mentioned a while ago, skills can be learned but attitude, the character, that's the thread. Totally different. Second is, there's a lot of path that you can take to be a data engineer. For example, in my case, my career is more on software development first and then I went through DevOps, infrastructure, scalability. Those kind of things, you can make use of your foundation also to become a data engineer. But it's also hard. As I mentioned, it's not hard. For example, if you're going to be a fresh grad, you will be working with actual data right away. I actually hired someone from UP last year who is very good in data science as a data engineer because the work ethic is there. It all comes down to, learn how to break things, learn from it, apply it as much as you can, and continue growing. There's a lot of YouTube channels as well that have data engineering, what do you call that, maps? Skills map? That you can check in the internet. It's an interesting time to be in. A lot of things you can learn if you want to. I'll build on what both of the panelists have said. There's a huge amount of collateral out on the web that you can consume, probably more than you could ever consume in a lifetime. I think it's about being ready, ready, focused. I think the focus that you need to bring is around what is my body of work. There's a lot of people that will say, hey, I've gone and done a course, I've gone and done a cert, I've gone and done this, but where's the evidence that you've applied that? My advice would be build a portfolio, build a body of work, and you can do that in the absence of being in the work environment. One of the best ways is cacles. These data science and data engineering competitions. Find like-minded individuals, come together and go and solve tough problems using open data sets together, and then do it in the team sport-like manner that these companies require. The other thing is around how you work as a team player. There's a lot of individuals that are really, really good at football. You know, you want a team player, you want someone that's going to be fantastic at agricultural, but is able to work in a team to solve tough problems. So I'd say build a portfolio of work, demonstrate that you can do that in a team-like manner, demonstrate that you can solve tough data and AI problems, leverage all of the material that's out there. Databricks has a phenomenal amount of open, free learning. If you've not seen it, just go to our learning and enablement site. There's a huge amount there. We're running training pretty much any day of the given week, so check it out. And then specifically for the University of the Philippines, and I'd say this to the university, but I'd say this to all of our corporate customers and prospects, we want to know who you're working with from an academic faculty relationship perspective. That's important to us. We have an alliance program around universities. So if there's universities, academic relationships, faculty members that you have, let us know, because we want to build and invest in the talent of the future. So we do have a university alliance program. We provide resources, labs, learning material to those universities to go and run and train people on Databricks. So that's our kind of commitment back to the universities and the talent of the future. Cool. Lovely question. Love that. That's awesome. Thank you.\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_mp3.transcribe_audio(show_output=True)\n",
    "\n",
    "transcript_text = test_mp3.transcript_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e91e0",
   "metadata": {},
   "source": [
    "- Save output as `.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c472089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript saved at: Data/Output/DE question (raw transcription).txt\n"
     ]
    }
   ],
   "source": [
    "test_mp3.save_txt('Data/Output/DE question (raw transcription)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e526a9e1",
   "metadata": {},
   "source": [
    "## B. `OpenAI_Summarizer`\n",
    "\n",
    "Recall also that we require `OpenAI_Summarizer` to have the following functions:\n",
    "- Compute input tokens from input transcript.\n",
    "- Summarize transcript using `openai.ChatCompletion.create()`\n",
    "- Save output summary as `.txt` file.\n",
    "- Produce a dictionary like `usage_dict` to indicate summarization cost.\n",
    "- Compute output tokens from output summary.\n",
    "\n",
    "### Methods\n",
    "\n",
    "- `num_tokens_from_input_string()`: Calculates the number of input tokens from the input transcript using a specified encoding and returns the count as an integer.\n",
    "- `summarize_text()`: Generates a summarized text using the OpenAI GPT-3 model given a system prompt and the input transcript, and returns the summarized text into `n_items` as a string. It also allows the option to display the summarized text as output and set the number of bullet points in the summary.\n",
    "    - If `n_items=None`, a random number of points is given.\n",
    "- `save_txt()`: Saves the generated summarized text to a text file with the specified export directory and returns a confirmation message indicating the saved file's location.\n",
    "- `get_price()`: Calculates the cost of generating the summarized text based on the number of tokens used and returns the cost as a dictionary.\n",
    "- `num_tokens_from_output_string()`: Calculates the number of output tokens from the output summary using a specified encoding and returns the count as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1bfa8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "class OpenAI_Summarizer:\n",
    "    \"\"\"\n",
    "    This class uses OpenAI's GPT-3 model to summarize a transcript into bullet points. It can calculate the number of tokens in the input and output text, estimate the price of generating the summary based on token usage, save the summary to a text file, and display notes if required.\n",
    "    \n",
    "    -----------\n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    transcript_text : str\n",
    "        The input transcript that needs to be summarized.\n",
    "\n",
    "    summarizer_model : str, optional (default=\"gpt-3.5-turbo\")\n",
    "        The OpenAI model to use for summarizing the transcript.\n",
    "\n",
    "    USD_per_1k : float, optional (default=0.002)\n",
    "        The price charged per 1,000 tokens used.\n",
    "\n",
    "    encoding_name : str, optional (default=\"cl100k_base\")\n",
    "        The encoding type to use for encoding the input and output text.\n",
    "\n",
    "    --------\n",
    "    Methods:\n",
    "    --------\n",
    "    num_tokens_from_input_string() -> int:\n",
    "        Calculates the number of tokens in the input text using the specified encoding and returns it.\n",
    "\n",
    "    summarize_text(system_prompt:str, n_items:int=None, model:str=\"gpt-3.5-turbo\", show_notes:bool=False) -> str:\n",
    "        Summarizes the input text into a bulleted list of n-items using the OpenAI GPT-3 model as default, given a system prompt, and returns the summarized text.\n",
    "\n",
    "    save_txt(export_dir):\n",
    "        Saves the summarized text to a text file with the specified export directory.\n",
    "\n",
    "    get_price() -> dict:\n",
    "        Calculates the price for generating the summarized text based on the number of tokens used, and returns it as a dictionary.\n",
    "\n",
    "    num_tokens_from_output_string(encoding_name:str=\"cl100k_base\") -> int:\n",
    "        Calculates the number of tokens from the output string.\n",
    "    \n",
    "    -----------\n",
    "    Attributes:\n",
    "    -----------\n",
    "    \n",
    "    transcript_text : str\n",
    "        The input transcript that needs to be summarized.\n",
    "\n",
    "    summarizer_model : str\n",
    "        The OpenAI model to use for summarizing the transcript.\n",
    "\n",
    "    USD_per_1k : float\n",
    "        The price charged per 1,000 tokens used.\n",
    "\n",
    "    encoding_name : str\n",
    "        The encoding type to use for encoding the input and output text.\n",
    "\n",
    "    input_encoding : tiktok.Encoding\n",
    "        The encoding used to encode the input text.\n",
    "\n",
    "    input_num_tokens : int\n",
    "        The number of tokens in the input text.\n",
    "\n",
    "    response : openai.api_models.ModelAPIResponse\n",
    "        The response object returned by the OpenAI API after generating the summarized text.\n",
    "\n",
    "    summarized_text : str\n",
    "        The summarized text in bullet-point form.\n",
    "\n",
    "    output_usage_dict : dict\n",
    "        A dictionary containing the token usage of the OpenAI API after generating the summarized text.\n",
    "\n",
    "    output_tokens_count : int\n",
    "        The total number of tokens used by the OpenAI API after generating the summarized text.\n",
    "\n",
    "    output_price_dict : dict\n",
    "        A dictionary containing the cost of generating the summarized text based on token usage.\n",
    "\n",
    "    ---------\n",
    "    Examples:\n",
    "    ---------\n",
    "    \n",
    "    # Create an instance of the OpenAI_Summarizer class\n",
    "    summarizer = OpenAI_Summarizer(transcript_text=\"This is an example transcript.\")\n",
    "\n",
    "    # Calculate the number of input tokens\n",
    "    num_input_tokens = summarizer.num_tokens_from_input_string()\n",
    "    \n",
    "    # Define role_txt for system_prompt\n",
    "    role_txt = \"'You are a graduating SHS student, excellent at summarizing notes in layman's terms.\"\n",
    "\n",
    "    # Summarize the transcript into 3 bullet points\n",
    "    summarized_text = summarizer.summarize_text(system_prompt=role_txt, n_items=3)\n",
    "\n",
    "    # Save the summarized text to a text file\n",
    "    summarizer.save_txt(export_dir=\"example_summarized_text\")\n",
    "\n",
    "    # Calculate the cost of generating the summary\n",
    "    output_price = summarizer.get_price()\n",
    "\n",
    "    # Calculate the number of output tokens\n",
    "    num_output_tokens = summarizer.num_tokens_from_output_string()\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 transcript_text:str, \n",
    "                 summarizer_model:str = \"gpt-3.5-turbo\", \n",
    "                 USD_per_1k:float = 0.002, \n",
    "                 encoding_name:str = \"cl100k_base\"):\n",
    "        \"\"\"\n",
    "        Initializes the instance of the OpenAI_Summarizer class with the input text, model, USD_per_1k, and encoding_name parameters.\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        transcript_text : str\n",
    "            The input text to be summarized.\n",
    "        summarizer_model : str, optional\n",
    "            The name of the OpenAI language model to be used for summarization. Default is \"gpt-3.5-turbo\".\n",
    "        USD_per_1k : float, optional\n",
    "            The cost of 1000 tokens in USD. Default is 0.002.\n",
    "        encoding_name : str, optional\n",
    "            The name of the encoding to be used for tokenization. Default is \"cl100k_base\".\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "        self.transcript_text = transcript_text\n",
    "        self.summarizer_model = summarizer_model\n",
    "        self.USD_per_1k = USD_per_1k\n",
    "        self.encoding_name = encoding_name\n",
    "        \n",
    "    def num_tokens_from_input_string(self) -> int:\n",
    "    \n",
    "        \"\"\"\n",
    "        Calculates the number of tokens in the input text using the specified encoding and returns it.\n",
    "\n",
    "        Returns:\n",
    "            An integer representing the number of tokens in the input text.\n",
    "        \"\"\"\n",
    "    \n",
    "        self.input_encoding = tiktoken.get_encoding(self.encoding_name)\n",
    "        self.input_num_tokens = len(self.input_encoding.encode(self.transcript_text))\n",
    "\n",
    "    def summarize_text(self, \n",
    "                       system_prompt:str, \n",
    "                       n_items:int = None, \n",
    "                       model:str = \"gpt-3.5-turbo\", \n",
    "                       show_notes:bool=False) -> str:\n",
    "        \"\"\"\n",
    "        Summarizes the input text into a bulleted list of n-items using the OpenAI GPT-3 model as default, \n",
    "        given a system prompt, and returns the summarized text.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        system_prompt: str\n",
    "            A prompt to be fed into the OpenAI API model.\n",
    "        \n",
    "        n_items: int\n",
    "            The number of bullet points the summarized text should contain.\n",
    "        \n",
    "        model: str\n",
    "            The OpenAI API model to use for the text summarization.\n",
    "        \n",
    "        show_notes: bool\n",
    "            If True, it prints the summarized text.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            The summarized text.\n",
    "\n",
    "        Prints:\n",
    "        -------\n",
    "        If show_notes=True, it prints the summarized text.\n",
    "\n",
    "        Exceptions:\n",
    "        -----------\n",
    "        Raises an OpenAI API Exception if there is an issue with the OpenAI API authentication.\n",
    "        \"\"\"\n",
    "        self.response = openai.ChatCompletion.create(\n",
    "            model=self.summarizer_model,\n",
    "            messages=[\n",
    "                {\"role\":\"system\", \n",
    "                 \"content\": system_prompt},\n",
    "                \n",
    "                {\"role\":\"user\", \n",
    "                 \"content\": f\"Summarize the following transcript into {n_items} key bullet points: '\\n{self.transcript_text}'\"}\n",
    "            ])\n",
    "\n",
    "        self.summarized_text = self.response['choices'][0]['message']['content']\n",
    "        self.output_usage_dict = dict(self.response['usage'])\n",
    "        self.output_tokens_count = self.output_usage_dict['total_tokens']\n",
    "\n",
    "        if show_notes==True:\n",
    "            print(self.summarized_text)\n",
    "    \n",
    "    def save_txt(self, export_dir): \n",
    "        \"\"\"\n",
    "        Saves the summarized text to a text file with the specified export directory.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        export_dir : str\n",
    "            The directory path where the summarized text will be saved as a .txt file.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \n",
    "        Prints:\n",
    "        -------\n",
    "        A message indicating where the summarized note was saved.\n",
    "        \"\"\"\n",
    "        with open(f\"{export_dir}.txt\", 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(self.summarized_text)\n",
    "            f.close()\n",
    "            \n",
    "        print(f\"Summarized note saved at: {export_dir}.txt\")\n",
    "        \n",
    "\n",
    "    def get_price(self) -> dict: \n",
    "        \"\"\"\n",
    "        Calculates the price for generating the summarized text based on the number of tokens used, and returns it as a dictionary.\n",
    "        \n",
    "        Parameters:\n",
    "        None\n",
    "        \n",
    "        Returns:\n",
    "        output_price_dict (dict): a dictionary containing the cost of generating the summarized text based on the number of tokens used.\n",
    "        \n",
    "        Prints:\n",
    "        None\n",
    "        \n",
    "        Raises:\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.output_price_dict = {k: v*(self.USD_per_1k/1000.0) for (k, v) in self.output_usage_dict.items()}\n",
    "\n",
    "    \n",
    "    def num_tokens_from_output_string(self, \n",
    "                                      encoding_name:str = \"cl100k_base\") -> int:\n",
    "        \"\"\"\n",
    "        Calculates the number of tokens in the output string using the specified encoding and returns it.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        encoding_name: str\n",
    "            The name of the encoding to use in the tokenization process.\n",
    "            Default is 'cl100k_base'.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        output_num_tokens: int\n",
    "            The number of tokens in the summarized output text.\n",
    "            \n",
    "        Raises:\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.output_encoding = tiktoken.get_encoding(self.encoding_name)\n",
    "        self.output_num_tokens = len(self.output_encoding.encode(self.summarized_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd71f0",
   "metadata": {},
   "source": [
    "### Demonstration\n",
    "\n",
    "- Initialize `OpenAI_Summarizer` using `transcript_text`, by defining `summarizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d086a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = OpenAI_Summarizer(transcript_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b2c21",
   "metadata": {},
   "source": [
    "- Preview price per 1000 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcae2a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.USD_per_1k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2209c",
   "metadata": {},
   "source": [
    "- Get token count.\n",
    "- Make it sure that it's <4096 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ab65f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.num_tokens_from_input_string()\n",
    "summarizer.input_num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2abe4",
   "metadata": {},
   "source": [
    "- Preview input token price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27621948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026579999999999998"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(summarizer.USD_per_1k/1000) * summarizer.input_num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffbcb61",
   "metadata": {},
   "source": [
    "- Define `role_txt`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1892a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_txt = \"You are a detail-oriented data science student from the Philippines, who can easily transcribe text to pure English.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416e2e2",
   "metadata": {},
   "source": [
    "- Start summarization into 7 points.\n",
    "- Show output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eedb516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The question is about advice for college or graduate students interested in pursuing a data engineering career and how to prepare for the transition to industry.\n",
      "- There are many online resources available, but it can be tricky to learn data engineering without working with actual data and a business case that provides value.\n",
      "- One piece of advice is to look for internships that expose students to that kind of environment.\n",
      "- Attitude, work ethic, and a drive to learn are important factors to consider when hiring data engineers.\n",
      "- Having a foundation in software development or other related fields can also be helpful in pursuing a career as a data engineer.\n",
      "- Building a portfolio and demonstrating that one can solve tough data and AI problems in a team-like manner is important.\n",
      "- Databricks has a lot of open, free learning and runs training programs, and they have a university alliance program where they offer resources to universities to train people on Databricks.\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "summarizer.summarize_text(role_txt, n_items=7, show_notes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a9de8b",
   "metadata": {},
   "source": [
    "- Preview output tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de9278e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.num_tokens_from_output_string()\n",
    "summarizer.output_num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3cbb91",
   "metadata": {},
   "source": [
    "## C. Determine total job price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7416d",
   "metadata": {},
   "source": [
    "- Check tokens used by gpt-3.5-turbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f62d4194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 1378, 'completion_tokens': 185, 'total_tokens': 1563}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.output_usage_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc01e18",
   "metadata": {},
   "source": [
    "- Calculate estimated price based on current token price of USD 0.002 per 1k tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e861de19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization Output Price (in USD): \n",
      " {'prompt_tokens': 0.0027559999999999998, 'completion_tokens': 0.00037, 'total_tokens': 0.003126}\n"
     ]
    }
   ],
   "source": [
    "summarizer.get_price()\n",
    "\n",
    "print(\"Summarization Output Price (in USD): \\n\", summarizer.output_price_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6ccc3",
   "metadata": {},
   "source": [
    "- Save output text as `QnA_summarized.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca228e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized note saved at: Data/Output/QnA_summarized.txt\n"
     ]
    }
   ],
   "source": [
    "summarizer.save_txt('Data/Output/QnA_summarized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48fe6a",
   "metadata": {},
   "source": [
    "## C. Preview Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c29991",
   "metadata": {},
   "source": [
    "- Preview and pretty print transcription price from using Whisper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28442dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcription_price': '0.039 USD'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'transcription_price' : f\"{test_mp3.total_price:.2} USD\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7047d4b",
   "metadata": {},
   "source": [
    "- Preview the dictionary of chat completion token prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc5a0527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 0.0027559999999999998,\n",
       " 'completion_tokens': 0.00037,\n",
       " 'total_tokens': 0.003126}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.output_price_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572420c",
   "metadata": {},
   "source": [
    "- Preview and pretty print chat completion total price from using GPT-3.5 turbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63c1abb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summarization_price': '0.0031 USD'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'summarization_price' : f\"{summarizer.output_price_dict['total_tokens']:.2} USD\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c34467",
   "metadata": {},
   "source": [
    "- Combine these price dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "914ea02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcription_price': '0.039 USD',\n",
       " 'summarization_price': '0.0031 USD',\n",
       " 'total_price': '0.042 USD'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'transcription_price':f\"{test_mp3.total_price:.2} USD\"} |\\\n",
    "{'summarization_price':f\"{summarizer.output_price_dict['total_tokens']:.2} USD\"} |\\\n",
    "{'total_price': f\"{(test_mp3.total_price + summarizer.output_price_dict['total_tokens']):.2} USD\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c72ba",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "While the classes `OpenAI_Transcriber` and `OpenAI_Summarizer` are already easy to use on their own, the next step is to combine them by creating a child class called `OpenAI_NoteTaker`:\n",
    "- A note-taking routine will always combine the transcription and summarization jobs, so it's logical to combine them.\n",
    "- `OpenAI_NoteTaker` must have the following functions that do:\n",
    "    - take notes\n",
    "    - save notes\n",
    "    - preview total job price via dictionaries.\n",
    "    \n",
    "**These will be done on the next part.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663950d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
